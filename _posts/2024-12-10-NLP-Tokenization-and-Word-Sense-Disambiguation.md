---
layout: post
math: true
toc: true
---
Tokenization in natural language processing (NLP)involves breaking down text into smaller units called tokens. These tokens can be words, characters, or subwords. This process is for preparing text for further processing.

## Word Tokenization
Word tokenization is the process of splitting text into individual words. 
Example: Input: "I like doing NLP" 
Tokens: ["I", "like", "doing", "NLP"]

